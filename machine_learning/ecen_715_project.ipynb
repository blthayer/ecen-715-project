{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ecen-715-project",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Xwl7Ty_YAeo_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Imports and Seeding"
      ]
    },
    {
      "metadata": {
        "id": "tMoJrBxwADre",
        "colab_type": "code",
        "outputId": "9b4afb20-57c4-4b7a-cb48-b1d4754278e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# TODO: seeding\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iM5uupH1AjHk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive, Read Data"
      ]
    },
    {
      "metadata": {
        "id": "voxj5yn5AlUQ",
        "colab_type": "code",
        "outputId": "16f7548b-c16a-4113-b247-ae66a5947fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "# This will mount your personal drive. Note you'll need to authenticate.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnEBTAQpBqOT",
        "colab_type": "code",
        "outputId": "00d27f41-bfcc-48ea-c2cf-4a1923d97f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Google doesn't seem to currently support accessing a folder which is shared\n",
        "# with you. So, I've uploaded 'all_data.csv' to my own drive. To run, you'll\n",
        "# need to do the same.\n",
        "# os.listdir('/content/drive/My Drive')\n",
        "# TODO: Remove row limitation.\n",
        "df = pd.read_csv('/content/drive/My Drive/all_data.csv', index_col=0, parse_dates=True,\n",
        "                 infer_datetime_format=True) #, nrows=(1/5)*60*24*7*4)\n",
        "# Why my 'tz_convert' line did nothing in combine_all_data.py, I don't know.\n",
        "df.index = pd.to_datetime(df.index, utc=True)\n",
        "# df.index = df.index.tz_localize('UTC')\n",
        "df = df.tz_convert('America/New_York')\n",
        "print('Data loaded.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6UtwjCzvP7uN",
        "colab_type": "code",
        "outputId": "30fae7f6-7f34-4e7c-8c79-9ca1e4c272e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2900
        }
      },
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.tail())\n",
        "# print(df.info())\n",
        "# Since our time is evenly spaced, linear interpolation should do.\n",
        "# Why this didn't take in the script that created the file, I'm not sure.\n",
        "df.interpolate(method='linear', inplace=True)\n",
        "# After interpolation, there's just one NaN left. Use forward and backfilling.\n",
        "df.fillna(method='ffill', inplace=True)\n",
        "df.fillna(method='backfill', inplace=True)\n",
        "# Confirm we got rid of all the NaNs.\n",
        "nan_count = df.isna().sum()\n",
        "nan_cols = nan_count > 0\n",
        "print('Columns with NaNs:')\n",
        "print(df.columns[nan_cols])\n",
        "print('NaN counts:')\n",
        "print(nan_count[nan_cols])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                           forecast_lbmp__capitl  forecast_lbmp__centrl  \\\n",
            "Time Stamp                                                                \n",
            "2016-01-01 00:00:00-05:00                  30.19                  13.04   \n",
            "2016-01-01 00:05:00-05:00                  30.19                  13.04   \n",
            "2016-01-01 00:10:00-05:00                  30.19                  13.04   \n",
            "2016-01-01 00:15:00-05:00                  30.19                  13.04   \n",
            "2016-01-01 00:20:00-05:00                  30.19                  13.04   \n",
            "\n",
            "                           forecast_lbmp__dunwod  forecast_lbmp__genese  \\\n",
            "Time Stamp                                                                \n",
            "2016-01-01 00:00:00-05:00                  25.79                  12.45   \n",
            "2016-01-01 00:05:00-05:00                  25.79                  12.45   \n",
            "2016-01-01 00:10:00-05:00                  25.79                  12.45   \n",
            "2016-01-01 00:15:00-05:00                  25.79                  12.45   \n",
            "2016-01-01 00:20:00-05:00                  25.79                  12.45   \n",
            "\n",
            "                           forecast_lbmp__hq  forecast_lbmp__hudvl  \\\n",
            "Time Stamp                                                           \n",
            "2016-01-01 00:00:00-05:00              10.47                 25.64   \n",
            "2016-01-01 00:05:00-05:00              10.47                 25.64   \n",
            "2016-01-01 00:10:00-05:00              10.47                 25.64   \n",
            "2016-01-01 00:15:00-05:00              10.47                 25.64   \n",
            "2016-01-01 00:20:00-05:00              10.47                 25.64   \n",
            "\n",
            "                           forecast_lbmp__longil  forecast_lbmp__mhkvl  \\\n",
            "Time Stamp                                                               \n",
            "2016-01-01 00:00:00-05:00                   27.7                 13.53   \n",
            "2016-01-01 00:05:00-05:00                   27.7                 13.53   \n",
            "2016-01-01 00:10:00-05:00                   27.7                 13.53   \n",
            "2016-01-01 00:15:00-05:00                   27.7                 13.53   \n",
            "2016-01-01 00:20:00-05:00                   27.7                 13.53   \n",
            "\n",
            "                           forecast_lbmp__millwd  forecast_lbmp__nyc  ...  \\\n",
            "Time Stamp                                                            ...   \n",
            "2016-01-01 00:00:00-05:00                   25.9               25.84  ...   \n",
            "2016-01-01 00:05:00-05:00                   25.9               25.84  ...   \n",
            "2016-01-01 00:10:00-05:00                   25.9               25.84  ...   \n",
            "2016-01-01 00:15:00-05:00                   25.9               25.84  ...   \n",
            "2016-01-01 00:20:00-05:00                   25.9               25.84  ...   \n",
            "\n",
            "                           drybulbtemperature_e  relativehumidity_e  \\\n",
            "Time Stamp                                                            \n",
            "2016-01-01 00:00:00-05:00                  32.0                85.0   \n",
            "2016-01-01 00:05:00-05:00                  32.0                85.0   \n",
            "2016-01-01 00:10:00-05:00                  32.0                85.0   \n",
            "2016-01-01 00:15:00-05:00                  32.0                85.0   \n",
            "2016-01-01 00:20:00-05:00                  32.0                85.0   \n",
            "\n",
            "                           windspeed_e  windspeed_g  drybulbtemperature_i  \\\n",
            "Time Stamp                                                                  \n",
            "2016-01-01 00:00:00-05:00          8.0     1.000000                  54.0   \n",
            "2016-01-01 00:05:00-05:00          8.0     1.083333                  54.0   \n",
            "2016-01-01 00:10:00-05:00          8.0     1.166667                  54.0   \n",
            "2016-01-01 00:15:00-05:00          8.0     1.250000                  54.0   \n",
            "2016-01-01 00:20:00-05:00          8.0     1.333333                  54.0   \n",
            "\n",
            "                           relativehumidity_i  windspeed_i  \\\n",
            "Time Stamp                                                   \n",
            "2016-01-01 00:00:00-05:00               100.0         10.0   \n",
            "2016-01-01 00:05:00-05:00               100.0         10.0   \n",
            "2016-01-01 00:10:00-05:00               100.0         10.0   \n",
            "2016-01-01 00:15:00-05:00               100.0         10.0   \n",
            "2016-01-01 00:20:00-05:00               100.0         10.0   \n",
            "\n",
            "                           drybulbtemperature_j  relativehumidity_j  \\\n",
            "Time Stamp                                                            \n",
            "2016-01-01 00:00:00-05:00                  43.0                58.0   \n",
            "2016-01-01 00:05:00-05:00                  43.0                58.0   \n",
            "2016-01-01 00:10:00-05:00                  43.0                58.0   \n",
            "2016-01-01 00:15:00-05:00                  43.0                58.0   \n",
            "2016-01-01 00:20:00-05:00                  43.0                58.0   \n",
            "\n",
            "                           windspeed_j  \n",
            "Time Stamp                              \n",
            "2016-01-01 00:00:00-05:00         17.0  \n",
            "2016-01-01 00:05:00-05:00         17.0  \n",
            "2016-01-01 00:10:00-05:00         17.0  \n",
            "2016-01-01 00:15:00-05:00         17.0  \n",
            "2016-01-01 00:20:00-05:00         17.0  \n",
            "\n",
            "[5 rows x 135 columns]\n",
            "                           forecast_lbmp__capitl  forecast_lbmp__centrl  \\\n",
            "Time Stamp                                                                \n",
            "2018-12-31 18:35:00-05:00                  43.42                  24.76   \n",
            "2018-12-31 18:40:00-05:00                  43.42                  24.76   \n",
            "2018-12-31 18:45:00-05:00                  43.42                  24.76   \n",
            "2018-12-31 18:50:00-05:00                  43.42                  24.76   \n",
            "2018-12-31 18:55:00-05:00                  43.42                  24.76   \n",
            "\n",
            "                           forecast_lbmp__dunwod  forecast_lbmp__genese  \\\n",
            "Time Stamp                                                                \n",
            "2018-12-31 18:35:00-05:00                  38.84                  23.66   \n",
            "2018-12-31 18:40:00-05:00                  38.84                  23.66   \n",
            "2018-12-31 18:45:00-05:00                  38.84                  23.66   \n",
            "2018-12-31 18:50:00-05:00                  38.84                  23.66   \n",
            "2018-12-31 18:55:00-05:00                  38.84                  23.66   \n",
            "\n",
            "                           forecast_lbmp__hq  forecast_lbmp__hudvl  \\\n",
            "Time Stamp                                                           \n",
            "2018-12-31 18:35:00-05:00               21.0                 38.66   \n",
            "2018-12-31 18:40:00-05:00               21.0                 38.66   \n",
            "2018-12-31 18:45:00-05:00               21.0                 38.66   \n",
            "2018-12-31 18:50:00-05:00               21.0                 38.66   \n",
            "2018-12-31 18:55:00-05:00               21.0                 38.66   \n",
            "\n",
            "                           forecast_lbmp__longil  forecast_lbmp__mhkvl  \\\n",
            "Time Stamp                                                               \n",
            "2018-12-31 18:35:00-05:00                  52.74                 24.82   \n",
            "2018-12-31 18:40:00-05:00                  52.74                 24.82   \n",
            "2018-12-31 18:45:00-05:00                  52.74                 24.82   \n",
            "2018-12-31 18:50:00-05:00                  52.74                 24.82   \n",
            "2018-12-31 18:55:00-05:00                  52.74                 24.82   \n",
            "\n",
            "                           forecast_lbmp__millwd  forecast_lbmp__nyc  ...  \\\n",
            "Time Stamp                                                            ...   \n",
            "2018-12-31 18:35:00-05:00                  39.01                39.0  ...   \n",
            "2018-12-31 18:40:00-05:00                  39.01                39.0  ...   \n",
            "2018-12-31 18:45:00-05:00                  39.01                39.0  ...   \n",
            "2018-12-31 18:50:00-05:00                  39.01                39.0  ...   \n",
            "2018-12-31 18:55:00-05:00                  39.01                39.0  ...   \n",
            "\n",
            "                           drybulbtemperature_e  relativehumidity_e  \\\n",
            "Time Stamp                                                            \n",
            "2018-12-31 18:35:00-05:00             33.564054           85.652008   \n",
            "2018-12-31 18:40:00-05:00             33.577438           85.653920   \n",
            "2018-12-31 18:45:00-05:00             33.590822           85.655832   \n",
            "2018-12-31 18:50:00-05:00             33.604207           85.657744   \n",
            "2018-12-31 18:55:00-05:00             33.617591           85.659656   \n",
            "\n",
            "                           windspeed_e  windspeed_g  drybulbtemperature_i  \\\n",
            "Time Stamp                                                                  \n",
            "2018-12-31 18:35:00-05:00    13.520076          4.0             39.886364   \n",
            "2018-12-31 18:40:00-05:00    13.539197          4.0             39.954545   \n",
            "2018-12-31 18:45:00-05:00    13.558317          4.0             40.022727   \n",
            "2018-12-31 18:50:00-05:00    13.577438          4.0             40.090909   \n",
            "2018-12-31 18:55:00-05:00    13.596558          4.0             40.159091   \n",
            "\n",
            "                           relativehumidity_i  windspeed_i  \\\n",
            "Time Stamp                                                   \n",
            "2018-12-31 18:35:00-05:00           95.556818     7.704545   \n",
            "2018-12-31 18:40:00-05:00           95.522727     7.681818   \n",
            "2018-12-31 18:45:00-05:00           95.488636     7.659091   \n",
            "2018-12-31 18:50:00-05:00           95.454545     7.636364   \n",
            "2018-12-31 18:55:00-05:00           95.420455     7.613636   \n",
            "\n",
            "                           drybulbtemperature_j  relativehumidity_j  \\\n",
            "Time Stamp                                                            \n",
            "2018-12-31 18:35:00-05:00                  44.0           87.611111   \n",
            "2018-12-31 18:40:00-05:00                  44.0           87.888889   \n",
            "2018-12-31 18:45:00-05:00                  44.0           88.166667   \n",
            "2018-12-31 18:50:00-05:00                  44.0           88.444444   \n",
            "2018-12-31 18:55:00-05:00                  44.0           88.722222   \n",
            "\n",
            "                           windspeed_j  \n",
            "Time Stamp                              \n",
            "2018-12-31 18:35:00-05:00     8.722222  \n",
            "2018-12-31 18:40:00-05:00     8.777778  \n",
            "2018-12-31 18:45:00-05:00     8.833333  \n",
            "2018-12-31 18:50:00-05:00     8.888889  \n",
            "2018-12-31 18:55:00-05:00     8.944444  \n",
            "\n",
            "[5 rows x 135 columns]\n",
            "Columns with NaNs:\n",
            "Index([], dtype='object')\n",
            "NaN counts:\n",
            "Series([], dtype: int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "msJRxFsiaOCU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Split Data Into Testing vs. Training, Extract Feature We'll be Predicting"
      ]
    },
    {
      "metadata": {
        "id": "dbq_7lFnaW4s",
        "colab_type": "code",
        "outputId": "33bdd6b4-c479-458e-be5a-54f33ee5d60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's look at realtime LBMP in NYC.\n",
        "y = df['realtime_lbmp__nyc']\n",
        "x = df.drop(labels='realtime_lbmp__nyc', axis=1)\n",
        "\n",
        "# TODO: We probably shouldn't be using real-time data in training/predicting,\n",
        "# right? This should maybe be a two-step process: Predict 5-minute real-time \n",
        "# (will need another network/model to do that), then plug that in for LMP\n",
        "# training/predicting.\n",
        "y_train = y['2016':'2017']\n",
        "y_test = y['2018']\n",
        "x_train = x['2016':'2017']\n",
        "x_test = x['2018']\n",
        "\n",
        "print('Data split for train vs. test.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data split for train vs. test.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2RgObSfLZ6qL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scale Data"
      ]
    },
    {
      "metadata": {
        "id": "ZfxOgfynZ9VK",
        "colab_type": "code",
        "outputId": "8407aea9-4f24-4b2c-e181-9170e99a980d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# We'll use \"standard\" scaling\n",
        "# Scale y data.\n",
        "scaler_y = StandardScaler()\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
        "# \n",
        "scaler_x = StandardScaler()\n",
        "x_train_scaled = scaler_x.fit_transform(x_train.values)\n",
        "x_test_scaled = scaler_x.transform(x_test.values)\n",
        "print('Data has been scaled.')\n",
        "\n",
        "# Ensure we have no NaNs.\n",
        "np.isnan(x_train_scaled).any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has been scaled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "yFienfYUn1O2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create and Train Simple ANN"
      ]
    },
    {
      "metadata": {
        "id": "Wg_cfk55n3Nn",
        "colab_type": "code",
        "outputId": "e6b83f2f-74cf-4c6d-ecb1-a658fd1d1bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "cell_type": "code",
      "source": [
        "# This is just a silly simple ANN. Neurons per layer were selected with barely\n",
        "# any thought (except that people tend to use numbers which are powers of 2).\n",
        "ann = Sequential()\n",
        "ann.add(Dense(x_train.shape[1], input_dim=x_train.shape[1], activation='relu'))\n",
        "ann.add(Dense(256, activation='relu'))\n",
        "ann.add(Dense(128, activation='relu'))\n",
        "ann.add(Dense(64, activation='relu'))\n",
        "ann.add(Dense(1))\n",
        "\n",
        "ann.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "ann.fit(x_train_scaled, y_train_scaled, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "210528/210528 [==============================] - 27s 130us/step - loss: 0.1622 - mean_squared_error: 0.1622\n",
            "Epoch 2/10\n",
            "210528/210528 [==============================] - 25s 117us/step - loss: 0.0803 - mean_squared_error: 0.0803\n",
            "Epoch 3/10\n",
            "210528/210528 [==============================] - 26s 123us/step - loss: 0.0968 - mean_squared_error: 0.0968\n",
            "Epoch 4/10\n",
            "210528/210528 [==============================] - 25s 117us/step - loss: 0.0557 - mean_squared_error: 0.0557\n",
            "Epoch 5/10\n",
            "210528/210528 [==============================] - 25s 117us/step - loss: 0.0551 - mean_squared_error: 0.0551\n",
            "Epoch 6/10\n",
            "210528/210528 [==============================] - 26s 122us/step - loss: 0.0464 - mean_squared_error: 0.0464\n",
            "Epoch 7/10\n",
            "210528/210528 [==============================] - 26s 124us/step - loss: 0.0655 - mean_squared_error: 0.0655\n",
            "Epoch 8/10\n",
            "210528/210528 [==============================] - 25s 117us/step - loss: 0.0583 - mean_squared_error: 0.0583\n",
            "Epoch 9/10\n",
            "210528/210528 [==============================] - 26s 122us/step - loss: 0.0538 - mean_squared_error: 0.0538\n",
            "Epoch 10/10\n",
            "210528/210528 [==============================] - 24s 116us/step - loss: 0.0329 - mean_squared_error: 0.0329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f07289cdc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "oCZb5FTTt7Yx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict with ANN"
      ]
    },
    {
      "metadata": {
        "id": "fqyHRJRQuAKm",
        "colab_type": "code",
        "outputId": "97743126-8007-4280-9d93-21bbc5f1ea6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(x_test_scaled)\n",
        "\n",
        "# NOTE:\n",
        "# No parameter tuning, no stopping criterion, and we're not doing too badly. \n",
        "\n",
        "# TODO: Move this import - inline imports are poor form.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_pred, y_test_scaled)\n",
        "# If our predictions were perfect, they'd fall exactly on this line.\n",
        "plt.plot([-20, 50], [-20,50])\n",
        "plt.xlabel('prediction')\n",
        "plt.ylabel('actual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZGklChERCSp/w+aqNAh5QuwZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "H3zu8is44-6z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# To start, try a \"simple\" 1D CNN"
      ]
    },
    {
      "metadata": {
        "id": "wK23ZEzf5GVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Benefit to the 1D CNN: We don't have to reshape our data in a complicated manner\n",
        "# Cons: TBD\n",
        "\n",
        "# TODO: Finish this up. Ran out of time :/ \n",
        "# In the section below (Reshape Data for 2D CNN) there are some useful \n",
        "# constants, etc. We may need to do some simple data reshaping for this 1D CNN,\n",
        "# like arranging the data into batches. Take a look at what was done for the \n",
        "# section below. Note that here, we would likely just have to group the data\n",
        "# into 4-week batches to pass in for convolution. To be honest, I'm not really\n",
        "# sure how this 1D convolution works though.\n",
        "\n",
        "# https://keras.io/layers/convolutional/\n",
        "cnn1d = Sequential()\n",
        "# Kernel size of 36 - 3 hours of 5 minute windows?\n",
        "cnn1d.add(Conv1D(filters=32, kernel_size=36, padding='same', input_shape=()))\n",
        "cnn1d.add(Flatten())\n",
        "cnn1d.add(Dense(64, activation='relu'))\n",
        "cnn1d.add(Dense())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DBXaMW_bVvK6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reshape Data for 2D CNN"
      ]
    },
    {
      "metadata": {
        "id": "9bDcBV_4Vy6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: revisit this and get it working. 2D convolutional would be quite \n",
        "# interesting.\n",
        "\n",
        "# # How many full weeks do we have?\n",
        "# five_min_per_week = int((1/5) * 60 * 24 * 7)\n",
        "# # Given the shape of our data, how many weeks are there? (round down)\n",
        "# weeks_train = np.floor(x_train_scaled.shape[0] / five_min_per_week).astype(int)\n",
        "# weeks_test = np.floor(x_test_scaled.shape[0] / five_min_per_week).astype(int)\n",
        "# # Given how many weeks we have and assuming we train with 4 week batches, how\n",
        "# # many batches will we have?\n",
        "# batches_train = int(np.floor(weeks_train) / 4)\n",
        "# batches_test = int(np.floor(weeks_test) / 4)\n",
        "# # Determine the ending index of the data we'll keep (trim off the end)\n",
        "# keep_train = five_min_per_week * batches_train\n",
        "# keep_test = five_min_per_week * batches_test\n",
        "\n",
        "# # Trim the training and testing data.\n",
        "\n",
        "# x_train_scaled_keep = x_train_scaled[0:keep_train, :]\n",
        "# print('Trimmed traning data shape:')\n",
        "# print(x_train_scaled_keep.shape)\n",
        "# y_train_scaled_keep = y_train_scaled[0:keep_train]\n",
        "# print(y_train_scaled_keep.shape)\n",
        "\n",
        "# x_test_scaled_keep = x_test_scaled[0:keep_test, :]\n",
        "# y_test_scaled_keep = y_test_scaled[0:keep_test]\n",
        "# print(x_test_scaled_keep.shape)\n",
        "# print(y_test_scaled_keep.shape)\n",
        "\n",
        "# # Reshape the data!\n",
        "# # Arrange the data so that we have (batch, height, width, channels). We'll first\n",
        "# # try with one \"month\" batches, so we'll have \"batches_train\" or \"batches_test\"\n",
        "# # of them. Each \"month\" is 4 weeks (the height) and has 2016 samples\n",
        "# #(five_min_per_week). Finally, we'll have a channel for each feature.\n",
        "# x_train_reshaped = np.zeros((batches_train, 4, five_min_per_week,\n",
        "#                              x_train_scaled_keep.shape[1]))\n",
        "# x_test_reshaped = np.zeros((batches_test, 4, five_min_per_week,\n",
        "#                             x_test_scaled_keep.shape[1]))\n",
        "# # TODO: how do we need to reshape the y's? Array of vectors? Row per \"month\"?\n",
        "\n",
        "# # Time steps per 4 week month:\n",
        "# t_per_m = five_min_per_week * 4\n",
        "\n",
        "# # Loop over the features\n",
        "# for f_idx in range(x_train_reshaped.shape[-1]):\n",
        "#   # Loop over the \"months\".\n",
        "#   for m_idx in range(batches_train):\n",
        "#     # Determine starting and ending index:\n",
        "#     start_idx = int(m_idx * t_per_m)\n",
        "#     end_idx = start_idx + t_per_m\n",
        "    \n",
        "#     # Extract the relevant portions of the training data.\n",
        "#     d_train = x_train_scaled_keep[start_idx:end_idx, f_idx]\n",
        "    \n",
        "#     # Reshape the training data.\n",
        "#     d_train_reshaped = np.reshape(d_train, newshape=(4, five_min_per_week))\n",
        "    \n",
        "#     # Place the data into the reshaped array.\n",
        "#     x_train_reshaped[m_idx, :, :, f_idx] = d_reshaped\n",
        "    \n",
        "#     # Repeat for the testing data. However, we'll bail if we get an index error.\n",
        "#     try:\n",
        "#       d_test = x_test_scaled_keep[start_idx:end_idx, f_idx]\n",
        "      \n",
        "#     except IndexError:\n",
        "#       pass\n",
        "#     else:\n",
        "#       try:\n",
        "#         d_test_reshaped = np.reshape(d_test, newshape=(4, five_min_per_week))\n",
        "#         x_test_reshaped[m_idx, :, :, f_idx] = d_test_reshaped\n",
        "#       except ValueError as e:\n",
        "#         print('m_idx: {}, f_idx: {}'.format(m_idx, f_idx))\n",
        "#         print('start_idx: {}, end_idx: {}'.format(start_idx, end_idx))\n",
        "#         print('Shape of x_test_scaled_keep: {}'.format(x_test_scaled_keep.shape))\n",
        "#         raise e\n",
        "    \n",
        "# print('Data reshaped.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J92bh13MQlzc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create 2D CNN"
      ]
    },
    {
      "metadata": {
        "id": "BnCguDPyQn2E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: This was left in an incomplete state.\n",
        "\n",
        "# # If training is taking too long, we may want to switch to 'SeperableConv2D'\n",
        "# # layers instead of simply Conv2D\n",
        "# model = Sequential()\n",
        "# # kernel size of 12, 4 will give us 12 5 minutes intervals and 4 weeks if the \n",
        "# # data is arranged in a weekly format.\n",
        "# # \n",
        "# # Using strides of 3, 1 so we traverse 15 minutes of data at a time.\n",
        "# model.add(Conv2D(filters=8, kernel_size=(12, 4), strides=(3, 1),\n",
        "#                  padding='same', data_format='channels_last',\n",
        "#                  input_shape=(4, five_min_per_week, x_train.shape[1])))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(1, activation='relu'))\n",
        "\n",
        "# model.compile(loss=keras.losses.mean_squared_error, optimizer='Adam',\n",
        "#               metrics=['accuracy'])\n",
        "# print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U60Rhpqbm0ew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train CNN"
      ]
    },
    {
      "metadata": {
        "id": "bNeioa_zm2We",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.fit()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}